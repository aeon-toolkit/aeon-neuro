{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Transformers in ``aeon_neuro``\n",
    "\n",
    "Most EEG analysis begins with some form of transform. These transforms take a single\n",
    "EEG (a possibly multivariate time series) and return a new series or a collection\n",
    "of series with different\n",
    "properties. Transformers for a single EEG all implement the ``aeon`` base class\n",
    "``BaseSeriesTransformer``. ``BaseSeriesTransformer`` classes follow the scikit learn model of ``fit`` and\n",
    "``transform``. They take a single EEG stored in a numpy array of shape ``(n_channels,\n",
    " n_timepoints)`` and return a transformed series, possibly of a different shape. The\n",
    "following transformers are available in the ``aeon_neuro`` package:\n",
    "\n",
    " - [The Band Power Transformer](#BandPowerTransformer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ``BandPowerTransformer``\n",
    "\n",
    "\n",
    "\n",
    "The ``BandPowerTransformer`` transforms each channel of an EEG independently into its\n",
    " frequency components using the Fourier transform. The power of these frequency components can be used to\n",
    "estimate the power within specific frequency bands. Commonly used power bands are\n",
    " alpha (8 – 13 Hz), beta (13 – 30 Hz), gamma (30 – 100 Hz), theta (4 – 8 Hz) and\n",
    " delta (1 – 4 Hz). The  ``BandPowerSeriesTransformer`` class estimates the\n",
    "power of an  EEG signal across these five physiological sub-bands using windowed FFTs\n",
    ". The transform involves segmenting or windowing a single channel, performing a Fourier transform on the window, then summing the power of the frequency components within defined frequency bands. This transformer is useful for extracting features from EEG signals that are relevant for classification tasks, such as sleep stage classification."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This example starts by simulating EEG-like series' with power law noise to\n",
    "demonstrate the ``BandPowerTransformer``. We simulate\n",
    "a single channel that transitions every 1000 timepoints from different [noise\n",
    "colours](https://en.wikipedia.org/wiki/Colors_of_noise), from red to\n",
    "pink to white to blue to violet noise. Specifically, the power $P(f)$ at frequency $f$ follows the relationship $P(f) \\propto \\frac{1}{f^\\beta}$, with the spectral exponent $\\beta$ changing every 1000 timepoints.\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-22T16:59:28.726349Z",
     "start_time": "2024-11-22T16:59:28.712917Z"
    }
   },
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from scipy.signal import fftconvolve, welch\n",
    "\n",
    "n_timepoints, sfreq, window_size = 1000, 256, 128\n",
    "\n",
    "\n",
    "def sim_powerlaw(sfreq, exponent, n_timepoints=1000, random_seed=0):\n",
    "    \"\"\"Simulate Gaussian noise with power law spectrum.\n",
    "    (https://gist.github.com/nmayorov/e01d7081471d8ef95c4c42c4b8144224)\"\"\"\n",
    "\n",
    "    rng = np.random.default_rng(seed=random_seed)\n",
    "    fir_coeffs = np.empty(n_timepoints)\n",
    "    fir_coeffs[0] = 1\n",
    "    for idx in range(1, len(fir_coeffs)):\n",
    "        fir_coeffs[idx] = (0.5 * exponent + idx - 1) / idx * fir_coeffs[idx - 1]\n",
    "\n",
    "    white_noise = rng.standard_normal(n_timepoints)\n",
    "    scale = sfreq ** (1 - exponent)\n",
    "\n",
    "    noise = fftconvolve(fir_coeffs, white_noise, axes=0)[:n_timepoints]\n",
    "\n",
    "    return (scale * sfreq ** (1 - exponent)) ** 0.5 * noise\n",
    "\n",
    "\n",
    "# define noise types\n",
    "noise_colors = [\"red\", \"pink\", \"white\", \"blue\", \"violet\"]\n",
    "noise_exponents = [2, 1, 0, -1, -2]\n",
    "\n",
    "# generate EEG and labels\n",
    "EEG = []\n",
    "for exponent in noise_exponents:\n",
    "    epoch = sim_powerlaw(sfreq, exponent, n_timepoints=n_timepoints, random_seed=0)\n",
    "    EEG.append(epoch)\n",
    "\n",
    "print(len(EEG))\n",
    "# EEG = np.array(EEG)\n",
    "# l = np.array(noise_colors)\n",
    "print(\" EEG typee = \", type(EEG))"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n",
      " EEG typee =  <class 'list'>\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": ""
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is apparent from plotting the different noise types side-by-side in the time and\n",
    "frequency domains that they are visually difficult to separate in the time domain, but near perfectly separable in the frequency domain - especially in δ, θ, α, β, and γ EEG sub-bands (dashed vertical lines). The `BandPowerSeriesTransformer` converts a single series into five series representing the power bands of an EEG signal changing over time.  The power is\n",
    "calculated by summing the squared magnitude of the FFT coefficients within each\n",
    "frequency band for any given interval. The transformer returns a 2D array with shape `\n",
    "(5_bands, n_timepoints//window_size)`, where each row represents a frequency band."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "def plot_time_domain(x, sfreq, ax):\n",
    "    \"\"\"Plot series.\"\"\"\n",
    "    x = (x - x.mean()) / x.std()\n",
    "    return ax.plot(np.arange(len(x)) / sfreq, x)[0]\n",
    "\n",
    "\n",
    "def plot_frequency_domain(x, sfreq, ax):\n",
    "    \"\"\"Plot power spectral density.\"\"\"\n",
    "    freqs, powers = welch(x, sfreq, nperseg=200)\n",
    "    powers /= np.sum(powers)\n",
    "    return ax.loglog(freqs, powers)[0]\n",
    "\n",
    "\n",
    "from aeon_neuro.transformations.series import BandPowerSeriesTransformer\n",
    "\n",
    "# δ, θ, α, β, and γ frequency bands\n",
    "freq_bands = BandPowerSeriesTransformer.FREQ_BANDS\n",
    "vlines = np.log([value[1] for value in freq_bands.values()])\n",
    "\n",
    "# setup plots\n",
    "fig, axs = plt.subplots(ncols=2, figsize=(10, 3))\n",
    "[ax.set_facecolor(\"gainsboro\") for ax in axs]\n",
    "axs[0].set_title(\"Time Domain\")\n",
    "axs[0].set_xlabel(\"( Sec. )\")\n",
    "axs[1].set_title(\"Frequency Domain\")\n",
    "axs[1].set_xlabel(\"log( Hz )\")\n",
    "axs[1].set_ylabel(\"log( PSD )\")\n",
    "[axs[1].axvline(x=vline, color=\"k\", ls=\"--\", lw=1) for vline in vlines]\n",
    "axs[1].legend([\"freq bands\"])\n",
    "\n",
    "for idx in range(len(noise_colors)):\n",
    "    x = EEG[idx * n_timepoints : (idx + 1) * n_timepoints]\n",
    "    plot_time_domain(x, sfreq, axs[0]).set(color=noise_colors[idx], lw=0.3)\n",
    "    plot_frequency_domain(x, sfreq, axs[1]).set(color=noise_colors[idx])"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": ""
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While this is a simplified example with artificially distinct frequency bands, real EEG data presents a more complex scenario. Powerband features might be effective for classifying broad brain states, such as sleep stages, but could be less effective for other experimental tasks.\n",
    "\n",
    "For instance, in the KDD dataset where the task is to classify whether a subject's hand is resting on a table (\"rest\") or raised (\"task\"), the powerband approach to feature selection yields only chance-level accuracy. In contrast, the [data loading example](data_loading.ipynb) shows that on the same dataset a time-domain method using convolution to extract features achieves a classification accuracy of 90%."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "from aeon.datasets import load_classification\n",
    "\n",
    "X_train, y_train = load_classification(\n",
    "    name=\"KDD_MTSC\", split=\"TRAIN\", extract_path=\"../aeon_neuro/data/KDD_Example\"\n",
    ")\n",
    "\n",
    "X_test, y_test = load_classification(\n",
    "    name=\"KDD_MTSC\", split=\"TEST\", extract_path=\"../aeon_neuro/data/KDD_Example\"\n",
    ")\n",
    "\n",
    "# reshape from collection to series, where y labels index time\n",
    "n_cases, n_channels, n_timepoints = X_train.shape\n",
    "assert X_train.shape == X_test.shape, \"X_train.shape != X_test.shape\"\n",
    "\n",
    "X_train = X_train.reshape(n_channels, n_timepoints * n_cases)\n",
    "y_train = y_train.repeat(n_timepoints / window_size)\n",
    "X_test = X_test.reshape(n_channels, n_timepoints * n_cases)\n",
    "y_test = y_test.repeat(n_timepoints / window_size)\n",
    "\n",
    "print(f\"X shape: {X_train.shape}\\ny shape: {y_train.shape}\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": "",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aeon-neuro",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
